{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecbfec70-c002-4abf-975e-50da60db61f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initializing Setup ---\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "import warnings\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"--- Initializing Setup ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66f09663-6d57-4fda-9e87-ae4760aff30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Set your Gemini API key (no ADC needed)\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyCmVuOO3WaW1h-bAJyH6YPQJqlGln_Bdu4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96517bf3-7d65-4e64-8fdb-a591de0f6acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF directory set to: C:\\Users\\agama\\OneDrive\\Desktop\\manuals\n"
     ]
    }
   ],
   "source": [
    "pdf_dir = r\"C:\\Users\\agama\\OneDrive\\Desktop\\manuals\"\n",
    "\n",
    "if not os.path.exists(pdf_dir):\n",
    "    raise FileNotFoundError(f\"Directory not found: {pdf_dir}\")\n",
    "\n",
    "print(\"PDF directory set to:\", pdf_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20757bc3-a619-4534-ab85-e72036affde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Document Ingestion and Preprocessing ---\n",
      "Loaded 142 pages from 3 PDF documents.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Starting Document Ingestion and Preprocessing ---\")\n",
    "\n",
    "#  Load Documents \n",
    "pdf_dir = r\"C:\\Users\\agama\\OneDrive\\Desktop\\manuals\"  # Your manuals folder\n",
    "\n",
    "if not os.path.exists(pdf_dir):\n",
    "    raise FileNotFoundError(f\"Directory not found: {pdf_dir}\")\n",
    "\n",
    "pdf_docs_paths = [os.path.join(pdf_dir, f) for f in os.listdir(pdf_dir) if f.endswith(\".pdf\")]\n",
    "\n",
    "all_docs = []\n",
    "for doc_path in pdf_docs_paths:\n",
    "    loader = PyPDFLoader(doc_path)\n",
    "    pages = loader.load_and_split()\n",
    "    all_docs.extend(pages)\n",
    "\n",
    "if not all_docs:\n",
    "    raise ValueError(f\"No PDF documents found in '{pdf_dir}'. Please check the folder.\")\n",
    "\n",
    "print(f\"Loaded {len(all_docs)} pages from {len(pdf_docs_paths)} PDF documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db7ea585-262b-41c6-b268-da73f77d97ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 142 pages into 294 chunks.\n"
     ]
    }
   ],
   "source": [
    "# split Documents into Chunks \n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "chunked_docs = text_splitter.split_documents(all_docs)\n",
    "print(f\"Split {len(all_docs)} pages into {len(chunked_docs)} chunks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13553984-0c4d-4770-b711-8dfc672499bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Initializing Indexing Process ---\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Initializing Indexing Process ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2455cfaf-a398-46b8-9d42-b8d42c326d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\agama\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize Embedding Model \n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model_kwargs = {'device': 'cpu'} # Change to 'cuda' for GPU\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b80c1a2-252a-480f-b6ac-6188735a5fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding model loaded.\n"
     ]
    }
   ],
   "source": [
    "print(\"Embedding model loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "063b2933-b5cc-491f-9afd-3b3f7905f6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing vector store...\n",
      "Vector store loaded.\n"
     ]
    }
   ],
   "source": [
    "db_path = \"faiss_index\"\n",
    "if os.path.exists(db_path):\n",
    "    print(\"Loading existing vector store...\")\n",
    "    db = FAISS.load_local(db_path, embeddings, allow_dangerous_deserialization=True)\n",
    "    print(\"Vector store loaded.\")\n",
    "else:\n",
    "    print(\"Creating new vector store...\")\n",
    "    db = FAISS.from_documents(chunked_docs, embeddings)\n",
    "    db.save_local(db_path)\n",
    "    print(f\"Vector store created and saved to {db_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d32ec42c-88de-4fac-94c7-ef5c5e635ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a retriever from the vector store\n",
    "retriever = db.as_retriever(search_kwargs={'k': 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "336d0045-2c0a-4ab5-b4d4-68d4a7b9e063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Building the Conversational RAG Chain ---\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Building the Conversational RAG Chain ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "861c2c97-5810-4f31-b5ab-4608b0be8e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Gemini initialized successfully\n"
     ]
    }
   ],
   "source": [
    "# ✅ Initialize Gemini LLM\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",   # or \"gemini-1.5-pro\"\n",
    "    temperature=0.1,\n",
    "    convert_system_message_to_human=True\n",
    ")\n",
    "\n",
    "# ✅ Memory for chat history\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "print(\"✅ Gemini initialized successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68786a3c-a82e-4392-a296-711487e1e52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_prompt_template = \"\"\"\n",
    "You are a helpful assistant that answers questions using the provided context from product manuals.\n",
    "\n",
    "Guidelines:\n",
    "- Only use the given context to answer. Do not use outside knowledge.\n",
    "- If the answer is not contained in the context, say: \"I don’t know based on the available manuals.\"\n",
    "- Always cite your source at the end of the answer in the format: [SOURCE: document_name, PAGE: page_number].\n",
    "- If multiple sources are relevant, include all of them.\n",
    "- Keep answers clear, concise, and user-friendly.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db4c4e5a-0230-4670-8fbf-ea6ad8d4fc6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Building the Conversational RAG Chain ---\n",
      "--- RAG Chain Ready ---\n"
     ]
    }
   ],
   "source": [
    "CUSTOM_QUESTION_PROMPT = PromptTemplate.from_template(custom_prompt_template)\n",
    "\n",
    "print(\"\\n--- Building the Conversational RAG Chain ---\")\n",
    "\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    combine_docs_chain_kwargs={\"prompt\": CUSTOM_QUESTION_PROMPT}\n",
    ")\n",
    "\n",
    "print(\"--- RAG Chain Ready ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc14a343-9e68-4e52-b5d7-ac7f5887e2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: I don’t know based on the available manuals.\n"
     ]
    }
   ],
   "source": [
    "query = \"How are you?\"\n",
    "result = qa_chain.invoke({\"question\": query})\n",
    "\n",
    "print(\"\\nAnswer:\", result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704fafee-42b0-4bad-ae4f-51cd0f7e4b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
